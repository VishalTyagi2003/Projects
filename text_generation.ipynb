{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Load your text data and preprocess it\n",
        "# Example: text = open('your_text_file.txt', 'r').read().lower()\n",
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'r').read().lower()\n",
        "\n",
        "# Define parameters and preprocess text\n",
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "# Prepare sequences and next characters\n",
        "sentences = []\n",
        "next_characters = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_characters.append(text[i + SEQ_LENGTH]) # Fixed indentation\n",
        "\n",
        "characters = sorted(set(text))\n",
        "char_to_index = {char: i for i, char in enumerate(characters)}\n",
        "index_to_char = {i: char for i, char in enumerate(characters)}\n",
        "\n",
        "# Prepare X and y datasets\n",
        "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_characters[i]]] = 1 # Fixed indentation\n",
        "\n",
        "# Define the model architecture (example: LSTM-based)\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(SEQ_LENGTH, len(characters))),\n",
        "    Dense(len(characters), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "# Train the model (example: with 10 epochs)\n",
        "model.fit(X, y, batch_size=128, epochs=10)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('textgenerator.model')\n",
        "\n",
        "# Now you can use this model for text generation"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_14qYN43HbiD",
        "outputId": "78bad129-0247-4e57-cff2-7e120cfeb8fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "2905/2905 [==============================] - 332s 114ms/step - loss: 2.3623\n",
            "Epoch 2/10\n",
            "2905/2905 [==============================] - 323s 111ms/step - loss: 2.0140\n",
            "Epoch 3/10\n",
            "2905/2905 [==============================] - 319s 110ms/step - loss: 1.8794\n",
            "Epoch 4/10\n",
            "2905/2905 [==============================] - 319s 110ms/step - loss: 1.7878\n",
            "Epoch 5/10\n",
            "2905/2905 [==============================] - 321s 111ms/step - loss: 1.7192\n",
            "Epoch 6/10\n",
            "2905/2905 [==============================] - 320s 110ms/step - loss: 1.6661\n",
            "Epoch 7/10\n",
            "2905/2905 [==============================] - 322s 111ms/step - loss: 1.6243\n",
            "Epoch 8/10\n",
            "2905/2905 [==============================] - 319s 110ms/step - loss: 1.5905\n",
            "Epoch 9/10\n",
            "2905/2905 [==============================] - 319s 110ms/step - loss: 1.5617\n",
            "Epoch 10/10\n",
            "2905/2905 [==============================] - 322s 111ms/step - loss: 1.5368\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load your trained model\n",
        "model = tf.keras.models.load_model('textgenerator.model')\n",
        "\n",
        "# Text preprocessing - Use the same text file as you used for training\n",
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'r').read().lower()  # Use the same preprocessing as training\n",
        "\n",
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "# Instead of subsetting, use the entire text for character set\n",
        "characters = sorted(set(text))  # Use the full text to get all characters\n",
        "char_to_index = {c: i for i, c in enumerate(characters)}\n",
        "index_to_char = {i: c for i, c in enumerate(characters)}\n",
        "\n",
        "# Now you can subset for generating sentences if you want\n",
        "text = text[30000:80000]\n",
        "sentences = []\n",
        "next_characters = []\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_characters.append(text[i + SEQ_LENGTH])\n",
        "\n",
        "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):\n",
        "        X[i, t, char_to_index[character]] = 1\n",
        "        y[i, char_to_index[next_characters[i]]] = 1\n",
        "\n",
        "# Function to sample the next character\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, character in enumerate(sentence):\n",
        "            x_pred[0, t, char_to_index[character]] = 1\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated\n",
        "\n",
        "# Generate text and display the output\n",
        "print('-------0.2--------')\n",
        "print(generate_text(300, 0.2))\n",
        "print('-------0.4--------')\n",
        "print(generate_text(300, 0.4))\n",
        "print('-------0.6--------')\n",
        "print(generate_text(300, 0.6))\n",
        "print('-------0.8--------')\n",
        "print(generate_text(300, 0.8))\n",
        "print('-------1--------')\n",
        "print(generate_text(300, 1.0))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LgstZrJtj6p",
        "outputId": "244358dd-0b58-4b2a-e1f6-4cf1976ba06f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------0.2--------\n",
            " him not to be their bedfellow.\n",
            "worthy come, my lord, and so man a good so longer.\n",
            "\n",
            "second murderer:\n",
            "sir, that i will be so more than you so son.\n",
            "\n",
            "prince:\n",
            "the come to the word the world be so more than he hath send\n",
            "and some heart of the brother to the best.\n",
            "\n",
            "cominius:\n",
            "why, so do man of the great of his son.\n",
            "\n",
            "cominius:\n",
            "why, sir, if thou su\n",
            "-------0.4--------\n",
            "n when the navel of the state was touch'd the dest.\n",
            "\n",
            "comentio:\n",
            "stand the cares of his thousand his son.\n",
            "\n",
            "second caurel:\n",
            "o, that he that i am contring and to have\n",
            "be more the breast be the behold to every\n",
            "the now a part of my soul of hath such and mening\n",
            "so meat be worth the consed of the bester\n",
            "that brother her sweet and so a grave a prin\n",
            "-------0.6--------\n",
            "will owe another.\n",
            "\n",
            "coriolanus:\n",
            "on fair gors; and he have first, that hath death\n",
            "the great and love to death, and thou sown\n",
            "the body refort that hath the grace for yoursel,\n",
            "and for their can very deach of the son\n",
            "that the world and love against them be to'th\n",
            "will give a hall be the latter love to she\n",
            "aither and crown a vice, should be so w\n",
            "-------0.8--------\n",
            "e thus descended,\n",
            "that hath beside well pley of will mourte\n",
            "that must be vinenty my bears mest.\n",
            "i seeving thing fallow for my boants,\n",
            "fir a body recompoce the ofe, by not the warrd.\n",
            "\n",
            "samplee:\n",
            "and call shall to him that it along, such a foul\n",
            "would as my fasting that be shall but a that belint.\n",
            "\n",
            "boltow:\n",
            "cittlemile coundill,\n",
            "my prise to disp\n",
            "-------1--------\n",
            "he people had more absolute power,\n",
            "i say my letter wadwingn wish her arm'd fouls\n",
            "or thund stre'd.\n",
            "\n",
            "madcalia:\n",
            "no, furs, but, for a carrow it me sap my seave.\n",
            "so, why, look now, garchin see down; in you\n",
            "so long a fallious we shomes; insunt, and\n",
            "be to muthreck, flard, of my chatchatume,\n",
            "whel! what, so trount father be cruel.\n",
            "\n",
            "menenimeren:\n",
            "\n",
            "c\n"
          ]
        }
      ]
    }
  ]
}