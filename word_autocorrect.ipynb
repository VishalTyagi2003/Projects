{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pattern\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSwnmglzopkD",
        "outputId": "62751afd-bd1f-4c27-ba67-4bdac8a981d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/22.2 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK57Z3fbngLx"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing regular expression\n",
        "import re\n",
        "\n",
        "# words\n",
        "w = []\n",
        "\n",
        "# reading text file\n",
        "with open('final.txt', 'r', encoding=\"utf8\") as f:\n",
        "    file_name_data = f.read()\n",
        "    file_name_data = file_name_data.lower()\n",
        "    w = re.findall('\\w+', file_name_data)\n",
        "\n",
        "# vocabulary\n",
        "main_set = set(w)"
      ],
      "metadata": {
        "id": "EzhZpLIinmJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to count the frequency\n",
        "# of the words in the whole text file\n",
        "\n",
        "\n",
        "def counting_words(words):\n",
        "    word_count = {}\n",
        "    for word in words:\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "    return word_count"
      ],
      "metadata": {
        "id": "7uVl1s98nu2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the probability of each word\n",
        "def prob_cal(word_count_dict):\n",
        "    probs = {}\n",
        "    m = sum(word_count_dict.values())\n",
        "    for key in word_count_dict.keys():\n",
        "        probs[key] = word_count_dict[key] / m\n",
        "    return probs"
      ],
      "metadata": {
        "id": "qFFG3Hu_n0XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LemmWord: extracting and adding\n",
        "# root word i.e.Lemma using pattern module\n",
        "import pattern\n",
        "from pattern.en import lemma, lexeme\n",
        "#from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def LemmWord(word):\n",
        "    return list(lexeme(wd) for wd in word.split())[0]"
      ],
      "metadata": {
        "id": "k-lsUWpLn4I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting letters from the words\n",
        "def DeleteLetter(word):\n",
        "    delete_list = []\n",
        "    split_list = []\n",
        "\n",
        "    # considering letters 0 to i then i to -1\n",
        "    # Leaving the ith letter\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "\n",
        "    for a, b in split_list:\n",
        "        delete_list.append(a + b[1:])\n",
        "    return delete_list"
      ],
      "metadata": {
        "id": "Mcx76CfOn6VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switching two letters in a word\n",
        "def Switch_(word):\n",
        "    split_list = []\n",
        "    switch_l = []\n",
        "\n",
        "    #creating pair of the words(and breaking them)\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "\n",
        "    #Printint the first word (i.e. a)\n",
        "    #then replacing the first and second character of b\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_list if len(b) >= 2]\n",
        "    return switch_l"
      ],
      "metadata": {
        "id": "lSIFN-OOn6_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Replace_(word):\n",
        "    split_l = []\n",
        "    replace_list = []\n",
        "\n",
        "    # Replacing the letter one-by-one from the list of alphs\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_list = [a + l + (b[1:] if len(b) > 1 else '')\n",
        "                    for a, b in split_l if b for l in alphs]\n",
        "    return replace_list"
      ],
      "metadata": {
        "id": "DGqKri6gn95k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_(word):\n",
        "    split_l = []\n",
        "    insert_list = []\n",
        "\n",
        "    # Making pairs of the split words\n",
        "    for i in range(len(word) + 1):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "\n",
        "    # Storing new words in a list\n",
        "    # But one new character at each location\n",
        "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_list = [a + l + b for a, b in split_l for l in alphs]\n",
        "    return insert_list"
      ],
      "metadata": {
        "id": "sP0S6qnnn_y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting all the words\n",
        "# in a set(so that no word will repeat)\n",
        "def colab_1(word, allow_switches=True):\n",
        "    colab_1 = set()\n",
        "    colab_1.update(DeleteLetter(word))\n",
        "    if allow_switches:\n",
        "        colab_1.update(Switch_(word))\n",
        "    colab_1.update(Replace_(word))\n",
        "    colab_1.update(insert_(word))\n",
        "    return colab_1\n",
        "\n",
        "# collecting words using by allowing switches\n",
        "def colab_2(word, allow_switches=True):\n",
        "    colab_2 = set()\n",
        "    edit_one = colab_1(word, allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = colab_1(w, allow_switches=allow_switches)\n",
        "            colab_2.update(edit_two)\n",
        "    return colab_2"
      ],
      "metadata": {
        "id": "DSmOIjuVoCFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only storing those values which are in the vocab\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    suggested_word = []\n",
        "    best_suggestion = []\n",
        "    suggested_word = list(\n",
        "        (word in vocab and word) or colab_1(word).intersection(vocab)\n",
        "        or colab_2(word).intersection(\n",
        "            vocab))\n",
        "\n",
        "    # finding out the words with high frequencies\n",
        "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "    return best_suggestion"
      ],
      "metadata": {
        "id": "LDDF3FjQoETg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "my_word = input(\"Enter any word:\")\n",
        "\n",
        "# Counting word function\n",
        "word_count = counting_words(main_set)\n",
        "\n",
        "# Calculating probability\n",
        "probs = prob_cal(word_count)\n",
        "\n",
        "# only storing correct words\n",
        "tmp_corrections = get_corrections(my_word, probs, main_set, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    if(i < 3):\n",
        "        print(word_prob[0])\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "b3hSiuSFoF3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftjtLEaMoLQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}